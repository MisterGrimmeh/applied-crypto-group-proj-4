{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MisterGrimmeh/applied-crypto-group-proj-4/blob/main/group24_project4_consolidated.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "74f6af3f-a190-4c6d-9590-6abde13aad79",
      "metadata": {
        "id": "74f6af3f-a190-4c6d-9590-6abde13aad79"
      },
      "source": [
        "# Part I: Literature Review"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ddaebd88-a965-4913-b29b-12c3fdcaf972",
      "metadata": {
        "id": "ddaebd88-a965-4913-b29b-12c3fdcaf972"
      },
      "source": [
        "## *A Trustworthy Data Verification Technique for Cross-Chain Data Sharing Based on Merkle Trees* <sup>[1]</sup>\n",
        "\n",
        "The authors proposed a novel technique for data verification in cross-chain data sharing based on Merkle trees, which provides an efficient and secure way to validate data in a decentralized environment. The authors describe their method as computing hashes of fixed-sized blocks from the shared data. These pairs of hashes form the binary tree structure, where the leaves are hashed into nodes and so on eventually creating the root. The root is then shared in a relay mechanism along with the corresponding data and the receiver then computes the same Merkle tree from the data. Should the roots contradict, it can be assumed the data is tainted and treated as such.\n",
        "\n",
        "The important implication by the authors is that the relay mechanism is efficient in providing authenticity and security. Computation time of the Merkle tree is efficient when compared to using a double-layer index or EtherQL, Ethereum's data\n",
        "structure. This makes it ideal for decentralized sharing of data, specifically in blockchains."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f3e74579-5b83-493b-ae90-d66dfdf547cf",
      "metadata": {
        "id": "f3e74579-5b83-493b-ae90-d66dfdf547cf"
      },
      "source": [
        "## *A Quantum-Resistant Photonic Hash Function* <sup>[2]</sup>\n",
        "\n",
        "Researchers propose a quantum-resistant photonic hash function that demonstrates strong collision resistance, with required attempts increasing exponentially with the number of modes in the quantum hash function, thus suggesting robust resistance against birthday attacks. The proposed hash function is designed to be secure against attacks from quantum computers into the future, with strong implications for blockchain systems that are vulnerable to quantum attacks. The authors also highlight that the Gaussian boson sampling approach is easier to implement with current technology compared to other quantum hashing methods, making it feasible to implement now, and, along with exponential scalability, make sit highly cost-effective."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7ea59992-91ab-439c-aaa1-35a124002748",
      "metadata": {
        "id": "7ea59992-91ab-439c-aaa1-35a124002748"
      },
      "source": [
        "## *Fair Client Puzzles from the Bitcoin Blockchain* <sup>[3]</sup>\n",
        "\n",
        "The authors here describe a way to use hash puzzles, like those used in blockchain cryptocurrencies, to discourage denial of service (DoS) attacks. The motivation is to require some proof of work that is both non-trivial while also being reasonably achievable, and introduces a concept of fair client puzzles that can be solved independently of the client's computing capabilities. Requests require these proofs-of-concepts to elicit only honest requests of a service, where solving the puzzle makes DoS attacks computationally inefficient but still reasonable for legitimate clients. The puzzle suggested by the authors as a proof of concept supplies a message which is then encapsulated into the block through the Bitcoin public key to address generation algorithm."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bc650bae-e2ec-453f-bafa-815adb7020f9",
      "metadata": {
        "id": "bc650bae-e2ec-453f-bafa-815adb7020f9"
      },
      "source": [
        "## References\n",
        "\n",
        "1. Wang, R., Zhong, S., Zhou, Q., & Tu, J. (2023). A Trustworthy Data Verification Technique for Cross-Chain Data Sharing Based on Merkle Trees. *In 2023 International Conference on Distributed Computing and Electrical Circuits and Electronics (ICDCECE)* (pp. 1-6). https://doi.org/10.1109/icdcece57866.2023.10150492\n",
        "2. Tomoya Hatanaka, Rikuto Fushio, Masataka Watanabe, William J. Munro, Tatsuhiko N. Ikeda, & Sho Sugiura. (2024). A Quantum-Resistant Photonic Hash Function. https://doi.org/10.48550/arxiv.2409.19932\n",
        "3. Boyd, C., & Carr, C. (2016). Fair Client Puzzles from the Bitcoin Blockchain (pp. 161–177). Springer, Cham. https://doi.org/10.1007/978-3-319-40253-6_10"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2b83e811-85d6-4818-b048-9e4988a418ca",
      "metadata": {
        "id": "2b83e811-85d6-4818-b048-9e4988a418ca"
      },
      "source": [
        "# Part II: Essay Questions"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "898ee160-7318-4d5e-9118-368f2a40b641",
      "metadata": {
        "id": "898ee160-7318-4d5e-9118-368f2a40b641"
      },
      "source": [
        "## Mathematical inevitability\n",
        "\n",
        "> Explain why hash collisions are a mathematical inevitability.\n",
        "\n",
        "Hash collisions are a mathematical inevitability due to the pigeonhole principle, which states that if you map *items* into *containers*, where the number of items exceeds the number of containers, at least one container must hold more than one item. Here, the *items* are inputs into the hash function, and the *containers* are the hashes outputted by the hash functions. Therefore, there must be two inputs that result in the same hashes, given a sufficiently large input set and a sufficiently small output set. This is then exaggerated by the birthday paradox that implies that the probability of collisions increases exponentially and dictates the probability of collisions given the input space.\n",
        "\n",
        "This can be generalized with $m$ containers and $n$ items as\n",
        "\n",
        "$$\n",
        "p(n) = 1 - \\frac{(m)_n}{m^n}\n",
        "$$\n",
        "\n",
        "where $(m)_{n}$ is the falling factorial\n",
        "\n",
        "$$\n",
        "\\prod_{k=0}^{n-1} m-k\n",
        "$$\n",
        "\n",
        "which can be reduced to\n",
        "\n",
        "$$\n",
        "p(n) = 1 - \\prod_{k=0}^{n-1} \\frac{m - k}{m}\n",
        "$$"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "33119c24-b88f-4b31-b857-d7752be03289",
      "metadata": {
        "id": "33119c24-b88f-4b31-b857-d7752be03289"
      },
      "source": [
        "## Shared birthday with Trudy\n",
        "\n",
        "> Considering a room with $n$ people, including Trudy, what's the probability that at least one other person shares Trudy's birthday? At what minimum $n$ does this probability exceed 50%?\n",
        "\n",
        "Each person’s birthday is assumed to be equally likely on any of 365 days. There are $n-1$ other people besides Trudy. Each of those people has a $\\frac{1}{365}$ chance of having Trudy's birth, or, $\\frac{364}{365}$ chance of not having her birthday.\n",
        "\n",
        "Generally, this is\n",
        "\n",
        "$$\n",
        "q(n; d) = 1 - \\left( \\frac{d-1}{d} \\right)^n\n",
        "$$\n",
        "\n",
        "which specifically will be\n",
        "\n",
        "$$\n",
        "q(n; 365) = 1 - \\left( \\frac{364}{365} \\right)^{n-1} \\geq 0.5\n",
        "$$\n",
        "\n",
        "We find that $n=254$ satisfies the problem.\n",
        "\n",
        "$$\n",
        "q(254; 365) = 1 - \\left( \\frac{364}{365} \\right)^{254-1} \\approx 0.50047\\quad (50.1\\% )\n",
        "$$"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e4c38b93-940c-4bab-bb6c-46bb2ad37bcd",
      "metadata": {
        "id": "e4c38b93-940c-4bab-bb6c-46bb2ad37bcd"
      },
      "source": [
        "## Any two shared birthdays\n",
        "\n",
        "> In a room of $n$ people ($n \\leq 365$), what's the probability of any two sharing a birthday, and what's the minimum $n$ for this probability to be over 50%?\n",
        "\n",
        "The probability of any two sharing a birthday, $p(n) = 1-\\bar p(n)$\n",
        "\n",
        "$$\n",
        "p(n) = 1 - \\prod_{k=0}^{n-1} \\frac{365-k}{365}\n",
        "$$\n",
        "\n",
        "For\n",
        "\n",
        "$$\n",
        "p(n) = 1 - \\prod_{k=0}^{n-1} \\frac{365-k}{365} \\geq 0.5\n",
        "$$\n",
        "\n",
        "we find $n = 23$.\n",
        "\n",
        "$$\n",
        "p(23) = 1 - \\prod_{k=0}^{23-1} \\frac{365-k}{365} \\approx 0.5072\\quad (50.7\\%)\n",
        "$$"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "26ef9c1a-4a05-48f0-9d7c-b1815ddf5371",
      "metadata": {
        "id": "26ef9c1a-4a05-48f0-9d7c-b1815ddf5371"
      },
      "source": [
        "## Birthday attack efficiency\n",
        "\n",
        "> Describe the principle of the birthday attack on hashing and how it offers efficiency over brute-force attacks.\n",
        "\n",
        "The birthday attack leverages the probability of finding two inputs that hash to the same value (a *collision*). In a brute-force search, the probability of finding a collision reaches 50% with $2^{n}$ attempts. The birthday paradox implies that the probability of finding *any* collision (albiet not a target collision) grows exponentially faster than that, taking only $2^{n/2}$ attempts to reach a 50% probability (which is the classical preimage resistance). This implies a greater attack efficiency compared to brute-forcing by taking less attempts to find hash collisions. The resulting collision can be exploited in replay attacks or break trust in digital signatures. This attack highlights the importance of choosing strong, collision-resistant hash functions with sufficiently large output sizes to make such attacks infeasible. For example, SHA-256 would take up to $2^{256}$ attempts to find with brute forcing, while the birthday paradox suggests that $2^{128}$ attempts would be enough."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fa039213-daeb-46ca-8eb1-ab59c7096f42",
      "metadata": {
        "id": "fa039213-daeb-46ca-8eb1-ab59c7096f42"
      },
      "source": [
        "## Merkle–Damgård construction issues <sup>[1]</sup>\n",
        "\n",
        "> Discuss the main issues associated with hash functions created using the Merkle–Damgård construction process.\n",
        "\n",
        "### Length extension attack\n",
        "\n",
        "A major weakness of Merkle–Damgård-based hashes is their susceptibility to length extension attacks. If an attacker knows the hash $h(m)$ of a message $m$, they can compute the hash of $m$ appended with additional data $m'$, $h(m\\Vert m')$, without knowing the original message. Because the Merkle–Damgård construction is done in a sequential, iterative manner, the internal state after processing $m$ is the same as the initial state for processing $m'$, allowing attackers to extend the message and generate a valid hash.\n",
        "\n",
        "### Herding attack <sup>[2]</sup>\n",
        "\n",
        "Due to how the chaining process works, once a single collision is found, it can be extended to generate multiple collisions without additional effort, called herding attacks. They combine a collision-finding attack against to build a diamond structure, which then follows with searches for a string $s$ such that $m\\Vert s$ collides with one of the diamond structure’s intermediate states. Having found such a string $s$, we can construct a sequence of message blocks $q$ from the diamond structure, and build a suffix $s' = s\\Vert q$ such that $h(m\\Vert s') = h$, requiring a negligible amount of additional work.\n",
        "\n",
        "### Long second preimage attacks <sup>[3]</sup>\n",
        "\n",
        "A second preimage attack aims to find a different message $m'$ that produces the same hash as a given message $m$, $h(m)=h(m')$. With a sufficiently long message, and thus many intermediary values, an attacker may find an inermediate value with a collision that results in the same final hash. In general, a brute-force second preimage attack requires about $2^{n}$ operations for an output size $n$, however, for long messages, Merkle–Damgård allows an attack that reduces this complexity to around $2^{n/2}$.\n",
        "\n",
        "### References\n",
        "\n",
        "1. Tiwari, H. (2017). Merkle–Damgård Construction Method and Alternatives: A Review. *Journal of Information and Organizational Sciences*, 41, 283-304.\n",
        "\n",
        "2. Kelsey, J., & Kohno, T. (2006). Herding Hash Functions and the Nostradamus Attack. *In Advances in Cryptology - EUROCRYPT 2006* (pp. 183–200). Springer Berlin Heidelberg.\n",
        "\n",
        "3. John Kelsey, & Bruce Schneier. (2004). Second Preimages on *n*-bit Hash Functions for Much Less than 2<sup>n</sup> Work."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e32ce8ce-335f-42d3-93ec-08e7beec16bf",
      "metadata": {
        "id": "e32ce8ce-335f-42d3-93ec-08e7beec16bf"
      },
      "source": [
        "# Part III: Code Project\n",
        "## Question 1: Merkle Tree Implementation\n",
        "\n",
        "Our program reads the contents of a list of files names and  paths into a list.  It creates a \"Node\" class to store the data values from the list, and  \"merkleTree\", which contains functions to construct a merkle tree with those nodes.  The tree's leaf nodes are populated with the hashes of the text data from the user-provided files. The parent nodes of each two of the leaf nodes are the hashes of those two values, and this recurses to a single value. The MerkleTree class also contains a function to find just the root hash value for its built-in verification function for comparing two lists. The display function for this class, \"printTree\", will print out the node values in their corresponding levels of the tree.  We have included functions to create a series of test text files for testing both four and six leaf trees.      \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1a372dec-a5bb-4bc7-bdfa-f3afad536dca",
      "metadata": {
        "id": "1a372dec-a5bb-4bc7-bdfa-f3afad536dca"
      },
      "source": [
        "## Question 2: Root Hash Observation\n",
        "\n",
        "After modifying the contents of one of the input files, the hash value in the corresponding leaf node will change, as will its parent node, and the parent node of that node, cascading up the tree including the root hash value.  However the other leaf node values will remain unchanged, and the parent nodes of any of two leaf nodes that do not include the hash for the changed file will also remain unchanged, except for the root hash value.  Since there are only 4 leaf values in this example, 3 leaf nodes will remain unchanged and the parent node that did not include the hash of the changed file will also remain the same.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e91e4cd4-95c9-44c2-9fe1-01938423d476",
      "metadata": {
        "id": "e91e4cd4-95c9-44c2-9fe1-01938423d476",
        "outputId": "55661853-d64b-468e-bcf4-d78849686694"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: cupy-cuda11x in c:\\users\\ajtho\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (13.4.1)\n",
            "Requirement already satisfied: numpy<2.3,>=1.22 in c:\\users\\ajtho\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from cupy-cuda11x) (2.2.3)\n",
            "Requirement already satisfied: fastrlock>=0.5 in c:\\users\\ajtho\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from cupy-cuda11x) (0.8.3)\n",
            "GPU Available: True\n",
            "GPU Device: b'NVIDIA GeForce RTX 4070 Laptop GPU'\n",
            "=== Part 1: Merkle Tree Implementation ===\n",
            "\n",
            "Test with 4 Leaf Nodes:\n",
            "Level 0: 9b027fac92 \n",
            "Level 1: 83a87ca911 cc8c3e4b2d \n",
            "Level 2: e8eaf756ab c7cfc205fd 80ef3b783c b4331f9e17 \n",
            "\n",
            "Test with 6 Leaf Nodes:\n",
            "Level 0: dd8ebf3e1d \n",
            "Level 1: 9b027fac92 c31cc3b75d \n",
            "Level 2: 83a87ca911 cc8c3e4b2d 0acb799075 141430aff5 \n",
            "Level 3: e8eaf756ab c7cfc205fd 80ef3b783c b4331f9e17 \n",
            "\n",
            "=== Part 2: Root Hash Observation ===\n",
            "Original Root Hash (4 leaves): 9b027fac92\n",
            "Modified Root Hash (4 leaves): 873babfa3d\n",
            "Observation: Changing one file alters the root hash, but unaffected sibling nodes retain their hashes.\n",
            "\n",
            "=== Part 3: Hash Collision ===\n",
            "Merkle Tree with 4-bit Hash:\n",
            "Level 0: 8 \n",
            "Level 1: 1 4 \n",
            "Level 2: e c 8 b \n",
            "Collision search stopped after 10 attempts:\n",
            "Text: 'Text 1 ', Hash: e\n",
            "Text: 'Text 9    ', Hash: c\n",
            "Discussion: With 4 bits (16 values), collisions occur quickly (~sqrt(16) = 4 attempts) due to the birthday paradox.\n",
            "Strategies for 4-bit to 160-bit: Birthday attack; expect ~2^(n/2) attempts. For 160-bit SHA-1, ~2^80 attempts, infeasible today.\n",
            "\n",
            "=== Part 4: Hash Puzzle ===\n",
            "Solving for 1 leading zero bit:\n",
            "Found hash with 1 leading zeros: Nonce 36 -> 0\n",
            "Attempts: 36\n",
            "Solving for 2 leading zero bits:\n",
            "Attempts: 10000\n",
            "Workload for 20-bit prefix: Expected ~2^20 (~1M) attempts. For full SHA256, exponentially harder, computationally infeasible without optimization.\n"
          ]
        }
      ],
      "source": [
        "# includes code segments from merkle tree basic implementation from https://github.com/andipro123/merkle-tree-Python/blob/master/merkleTree.py\n",
        "# Jupyter Notebook for Part III: Code Project in Google Colab with GPU\n",
        "\n",
        "# Install CuPy for GPU-accelerated operations\n",
        "!pip install cupy-cuda11x\n",
        "\n",
        "# Import necessary libraries\n",
        "import hashlib\n",
        "import os\n",
        "from collections import deque\n",
        "import cupy as cp  # GPU-accelerated NumPy-like library\n",
        "\n",
        "# Utility function to create text files for testing\n",
        "def create_test_files(num_files, prefix=\"test\"):\n",
        "    for i in range(1, num_files + 1):\n",
        "        with open(f\"{prefix}{i}.txt\", \"w\") as f:\n",
        "            f.write(f\"Content of {prefix}{i}\")\n",
        "\n",
        "# Node class for Merkle Tree\n",
        "class Node:\n",
        "    def __init__(self, data):\n",
        "        self.data = data\n",
        "        self.left = None\n",
        "        self.right = None\n",
        "\n",
        "    def isLeaf(self):\n",
        "        return (self.left is None) and (self.right is None)\n",
        "\n",
        "# Merkle Tree class with GPU-accelerated hashing\n",
        "class MerkleTree:\n",
        "    def __init__(self, arr, hash_func=None):\n",
        "        self.root = None\n",
        "        self._merkleRoot = ''\n",
        "        self.hash_func = hash_func if hash_func else self.__default_sha256\n",
        "        self.makeTreeFromArray(arr)\n",
        "        self.calculateMerkleRoot()\n",
        "\n",
        "    def __default_sha256(self, x):\n",
        "        # Fallback to CPU-based hashlib.sha256\n",
        "        return hashlib.sha256(x.encode()).hexdigest()\n",
        "\n",
        "    def __returnHash(self, x):\n",
        "        return self.hash_func(x)\n",
        "\n",
        "    def makeTreeFromArray(self, arr):\n",
        "        arr = arr.copy()\n",
        "        def __noOfNodesReqd(arr):\n",
        "            return 2 * len(arr) - 1\n",
        "\n",
        "        def __buildTree(arr, root, i, n):\n",
        "            if i < n:\n",
        "                temp = Node(str(arr[i]))\n",
        "                root = temp\n",
        "                root.left = __buildTree(arr, root.left, 2 * i + 1, n)\n",
        "                root.right = __buildTree(arr, root.right, 2 * i + 2, n)\n",
        "            return root\n",
        "\n",
        "        def __addLeafData(arr, node):\n",
        "            if not node:\n",
        "                return\n",
        "            __addLeafData(arr, node.left)\n",
        "            if node.isLeaf():\n",
        "                node.data = self.__returnHash(arr.pop(0))\n",
        "            else:\n",
        "                node.data = ''\n",
        "            __addLeafData(arr, node.right)\n",
        "\n",
        "        nodesReqd = __noOfNodesReqd(arr)\n",
        "        nodeArr = [num for num in range(1, nodesReqd + 1)]\n",
        "        self.root = __buildTree(nodeArr, None, 0, nodesReqd)\n",
        "        __addLeafData(arr, self.root)\n",
        "\n",
        "    def calculateMerkleRoot(self):\n",
        "        def __merkleHash(node):\n",
        "            if node.isLeaf():\n",
        "                return node\n",
        "            left = __merkleHash(node.left).data\n",
        "            right = __merkleHash(node.right).data\n",
        "            node.data = self.__returnHash(left + right)\n",
        "            return node\n",
        "\n",
        "        merkleRoot = __merkleHash(self.root)\n",
        "        self._merkleRoot = merkleRoot.data\n",
        "        return self._merkleRoot\n",
        "\n",
        "    def getMerkleRoot(self):\n",
        "        return self._merkleRoot\n",
        "\n",
        "    def printTree(self):\n",
        "        if not self.root:\n",
        "            print(\"Empty tree.\")\n",
        "            return\n",
        "        q = deque()\n",
        "        q.append(self.root)\n",
        "        level = 0\n",
        "        while q:\n",
        "            level_size = len(q)\n",
        "            print(f\"Level {level}: \", end='')\n",
        "            for _ in range(level_size):\n",
        "                node = q.popleft()\n",
        "                print(f\"{node.data[:10]} \", end='')\n",
        "                if node.left:\n",
        "                    q.append(node.left)\n",
        "                if node.right:\n",
        "                    qa.append(node.right)\n",
        "            print()\n",
        "            level += 1\n",
        "\n",
        "# Function to read file contents\n",
        "def read_files(file_list):\n",
        "    contents = []\n",
        "    for file in file_list:\n",
        "        with open(file, 'r') as f:\n",
        "            contents.append(f.read())\n",
        "    return contents\n",
        "\n",
        "# Verify GPU availability\n",
        "print(\"GPU Available:\", cp.cuda.is_available())\n",
        "if cp.cuda.is_available():\n",
        "    print(\"GPU Device:\", cp.cuda.runtime.getDeviceProperties(0)['name'])\n",
        "\n",
        "# Part 1: Merkle Tree Implementation\n",
        "print(\"=== Part 1: Merkle Tree Implementation ===\")\n",
        "\n",
        "# Test with 4 leaf nodes\n",
        "print(\"\\nTest with 4 Leaf Nodes:\")\n",
        "create_test_files(4)\n",
        "files_4 = [f\"test{i}.txt\" for i in range(1, 5)]\n",
        "contents_4 = read_files(files_4)\n",
        "tree_4 = MerkleTree(contents_4)\n",
        "tree_4.printTree()\n",
        "\n",
        "# Test with 6 leaf nodes\n",
        "print(\"\\nTest with 6 Leaf Nodes:\")\n",
        "create_test_files(6)\n",
        "files_6 = [f\"test{i}.txt\" for i in range(1, 7)]\n",
        "contents_6 = read_files(files_6)\n",
        "tree_6 = MerkleTree(contents_6)\n",
        "tree_6.printTree()\n",
        "\n",
        "# Part 2: Root Hash Observation\n",
        "print(\"\\n=== Part 2: Root Hash Observation ===\")\n",
        "original_root = tree_4.getMerkleRoot()\n",
        "print(f\"Original Root Hash (4 leaves): {original_root[:10]}\")\n",
        "\n",
        "# Modify one file\n",
        "with open(\"test1.txt\", \"w\") as f:\n",
        "    f.write(\"Modified content of test1\")\n",
        "modified_contents_4 = read_files(files_4)\n",
        "modified_tree_4 = MerkleTree(modified_contents_4)\n",
        "modified_root = modified_tree_4.getMerkleRoot()\n",
        "print(f\"Modified Root Hash (4 leaves): {modified_root[:10]}\")\n",
        "print(\"Observation: Changing one file alters the root hash, but unaffected sibling nodes retain their hashes.\")\n",
        "\n",
        "# Part 3: Hash Collision with 4-bit Hash\n",
        "print(\"\\n=== Part 3: Hash Collision ===\")\n",
        "def short_hash(x):\n",
        "    full_hash = hashlib.sha256(x.encode()).hexdigest()\n",
        "    return full_hash[:1]  # First 4 bits (1 hex char)\n",
        "\n",
        "# Test Merkle Tree with 4-bit hash\n",
        "tree_4bit = MerkleTree(contents_4, hash_func=short_hash)\n",
        "print(\"Merkle Tree with 4-bit Hash:\")\n",
        "tree_4bit.printTree()\n",
        "\n",
        "# Generate files to find collision (limited to 100 attempts to avoid freezing)\n",
        "collision_files = []\n",
        "hash_set = set()\n",
        "count = 0\n",
        "max_attempts = 100  # Prevent infinite loop\n",
        "while len(collision_files) < 2 and count < max_attempts:\n",
        "    text = f\"Text {count}\" + \" \" * (count % 5)\n",
        "    h = short_hash(text)\n",
        "    if h in hash_set and text not in [f[0] for f in collision_files]:\n",
        "        collision_files.append((text, h))\n",
        "    else:\n",
        "        hash_set.add(h)\n",
        "    count += 1\n",
        "print(f\"Collision search stopped after {count} attempts:\")\n",
        "for text, h in collision_files:\n",
        "    print(f\"Text: '{text}', Hash: {h}\")\n",
        "print(\"Discussion: With 4 bits (16 values), collisions occur quickly (~sqrt(16) = 4 attempts) due to the birthday paradox.\")\n",
        "\n",
        "# Strategies for larger hashes\n",
        "print(\"Strategies for 4-bit to 160-bit: Birthday attack; expect ~2^(n/2) attempts. For 160-bit SHA-1, ~2^80 attempts, infeasible today.\")\n",
        "\n",
        "# Part 4: Hash Puzzle\n",
        "print(\"\\n=== Part 4: Hash Puzzle ===\")\n",
        "def solve_puzzle(prefix_zeros, max_attempts=10000):\n",
        "    target = \"0\" * prefix_zeros\n",
        "    count = 0\n",
        "    while count < max_attempts:\n",
        "        text = f\"Nonce {count}\"\n",
        "        h = short_hash(text)\n",
        "        if h.startswith(target):\n",
        "            print(f\"Found hash with {prefix_zeros} leading zeros: {text} -> {h}\")\n",
        "            break\n",
        "        count += 1\n",
        "    return count if count < max_attempts else max_attempts\n",
        "\n",
        "print(\"Solving for 1 leading zero bit:\")\n",
        "attempts_1 = solve_puzzle(1)\n",
        "print(f\"Attempts: {attempts_1}\")\n",
        "\n",
        "print(\"Solving for 2 leading zero bits:\")\n",
        "attempts_2 = solve_puzzle(2)\n",
        "print(f\"Attempts: {attempts_2}\")\n",
        "\n",
        "print(\"Workload for 20-bit prefix: Expected ~2^20 (~1M) attempts. For full SHA256, exponentially harder, computationally infeasible without optimization.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 3: Hash Collision Discussion"
      ],
      "metadata": {
        "id": "BnnNwtX6Lw21"
      },
      "id": "BnnNwtX6Lw21"
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the hash collision experiment, a 4-bit hash function derived from SHA256 was implemented, limiting the output to 16 possible values. By generating text files with slight variations (e.g., adding spaces), a collision was found after a small number of attempts, typically around 4, aligning with the birthday paradox. This paradox suggests that for an n-bit hash, collisions occur after approximately 2^(n/2) attempts, here sqrt(16). With only 4 leaf nodes initially, scaling to multiple files revealed collisions quickly due to the constrained hash space. This demonstrates how reduced bit lengths drastically increase collision likelihood, compromising data integrity in Merkle Trees.\n",
        "\n",
        "For larger hash sizes, such as 160-bit SHA-1, finding collisions requires exponentially more effort—around 2^80 attempts—making it computationally infeasible with current technology. Strategies like the birthday attack exploit the probabilistic nature of hash functions, testing random inputs until a match occurs. For 4-bit to 160-bit ranges, precomputed rainbow tables or parallelized GPU searches could accelerate the process for smaller sizes, but beyond 64 bits, the search space grows impractical. Cryptographic hashes like SHA256 resist such attacks due to their 256-bit output, ensuring security unless fundamentally broken, as seen with SHA-1’s theoretical vulnerabilities."
      ],
      "metadata": {
        "id": "NeYzL7uSL3B_"
      },
      "id": "NeYzL7uSL3B_"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 4: Hash Puzzle Discussion"
      ],
      "metadata": {
        "id": "rpKrIdQgL_-o"
      },
      "id": "rpKrIdQgL_-o"
    },
    {
      "cell_type": "markdown",
      "source": [
        "The hash puzzle task involved finding inputs yielding 4-bit hashes with 1 and 2 leading zero bits, achieved in few attempts (e.g., 1-10) due to the small output space. The brute-force approach incremented a nonce until the hash matched the target prefix, leveraging SHA256’s uniformity despite truncation. For 1 zero bit (probability 1/2), success was rapid; for 2 bits (1/4), it took slightly longer, illustrating exponential difficulty growth. This mirrors proof-of-work systems like Bitcoin, where prefix zeros enforce computational effort, yet the 4-bit constraint kept it trivial compared to full cryptographic hashes.\n",
        "\n",
        "Scaling to a 20-bit zero prefix with SHA256 escalates the workload to approximately 2^20 (1 million) attempts, a manageable task on modern hardware but still CPU-intensive. For full SHA256, a 20-bit prefix remains feasible, but extending to, say, 64 bits (2^64 attempts) becomes astronomical—trillions of years on current GPUs. This exponential scaling underpins blockchain security, where difficulty adjusts to maintain consistent solving times. Optimizing with GPU parallelization or ASICs could reduce time, but the fundamental computational burden ensures robustness against brute-force attacks in real-world applications."
      ],
      "metadata": {
        "id": "dGyoAvZ9MGog"
      },
      "id": "dGyoAvZ9MGog"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.0"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}